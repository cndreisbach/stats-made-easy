{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The problem\n",
    "\n",
    "http://dasl.datadesk.com/data/view/15\n",
    "\n",
    "In May, 1978, Brink's Inc. was awarded a contract to collect coins from some 70,000 parking meters in New York City for delivery to the City Department of Finance. Sometime later the City became suspicious that not all of the money collected was being returned to the city. In April of 1978 five Brink's collectors were arrested and charged with grand larceny. They were subsequently convicted. The city sued Brink's for negligent supervision of its employees, seeking to recover the amount stolen. As the fact of theft had been established, a reasonable estimate of the amount stolen was acceptable to the judge.\n",
    "\n",
    "## Let's take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meter_records = pd.read_csv(\"data/parking-meters.tsv\", sep=\"\\t\")\n",
    "meter_records.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This didn't work well at all. This file must be poorly formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meter_records = pd.read_csv(\"data/parking-meters.tsv\", sep=\"\\t\", skiprows=1, header=None, \n",
    "                            names=[\"month\", \"total\", \"city\", \"brinks\"])\n",
    "meter_records.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meter_records.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at line 9. For some reason, we have a space in the number. I could remove that space, but judging from the other numbers, I'm not sure that's good data. I'm going to throw it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meter_records = pd.read_csv(\"data/parking-meters.tsv\", sep=\"\\t\", skiprows=[0,11], header=None, \n",
    "                            names=[\"month\", \"total\", \"city\", \"brinks\"])\n",
    "meter_records.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meter_records.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want a point of comparison each month to see the amount of money taken in, but each month has differing amounts of parking, so a simple comparison of the total doesn't make sense. If we compare the amount taken in to the amount taken in by city workers, that could work, as both should track. Let's verify that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meter_records.city.corr(meter_records.total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meter_records.plot(kind=\"scatter\", x=\"city\", y=\"total\", figsize=(10, 6))\n",
    "m, b = np.polyfit(meter_records.city, meter_records.total, 1)\n",
    "plt.plot(meter_records.city, m*meter_records.city + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a medium correlation -- not great, but not bad. I don't have anything else to use, so let's go with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meter_records['adj_revenue'] = meter_records['total'] / meter_records['city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meter_records.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see the mean adjusted revenue for months when Brinks was active (1) and not active (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meter_records.pivot_table(columns=['brinks'], values=['adj_revenue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The p-value\n",
    "\n",
    "There's definitely a difference, but is it random chance or is this actually significant? In order to find out, we want the _p-value_.\n",
    "\n",
    "What is a _p-value_?\n",
    "\n",
    "For a test of statistical significance, we start with the _null hypothesis_. This is the hypothesis that there's no relation between groups. It's generally the opposite of what we're testing for. In this case, the null hypothesis is that there's no relation between whether Brinks was operating the meters and the amount of revenue brought in.\n",
    "\n",
    "Once you have that, you compare your observed result -- in this case the difference in mean adjusted revenue for months when Brinks was active and when it was inactive -- to some statistical model to see how extreme your result is. Another way of looking at it is, given your observed result, what's the likelihood the null hypothesis is true?\n",
    "\n",
    "People argue about the next step, but it's an OK rule of thumb: p-values of < 0.05 mean the null hypothesis is most likely not true.\n",
    "\n",
    "Note that we never see the chance that our alternative hypothesis -- the thing we're testing for -- is true. We are accepting or rejecting the null hypothesis.\n",
    "\n",
    "### Shuffling labels\n",
    "\n",
    "There are complex formula-based ways to calculate the p-value. I don't know them. I have a computer, though, so I can use another way. We can shuffle the labels -- in this case, shuffle the \"brinks\" value to different months -- many times and record our results. Shuffling them assume they don't matter -- our null hypothesis. If we do this many times, we can get a distribution of results and then see where our observed result falls on that. I'm going to do this with Pandas, but there's other ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get our observed value.\n",
    "def mean_revenue_diff(df):\n",
    "    revenues = df.pivot_table(columns=['brinks'], values=['adj_revenue'])\n",
    "    return (revenues[0] - revenues[1])['adj_revenue']\n",
    "\n",
    "observed_mean_diff = mean_revenue_diff(meter_records)\n",
    "observed_mean_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Copy the table so we can mess with it.\n",
    "mr2 = meter_records.copy()\n",
    "mr2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Shuffle the Brinks column.\n",
    "mr2.brinks = np.random.permutation(mr2.brinks)\n",
    "mr2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mr2.pivot_table(columns=['brinks'], values=['adj_revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_revenue_diff(mr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_experiments = 10000\n",
    "results = []\n",
    "count = 0\n",
    "for _ in range(num_experiments):\n",
    "    mr2.brinks = np.random.permutation(mr2.brinks)\n",
    "    mean_diff = mean_revenue_diff(mr2)\n",
    "    results.append(mean_diff)\n",
    "    if observed_mean_diff >= 0 and mean_diff >= observed_mean_diff:\n",
    "        count += 1\n",
    "    elif observed_mean_diff < 0 and mean_diff <= observed_mean_diff:\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Observed difference of two means: %.2f\" % observed_mean_diff)\n",
    "print(count, \"out of\", num_experiments, \"experiments had a difference of two means \", end=\"\")\n",
    "if observed_mean_diff < 0:\n",
    "    print(\"less than or equal to \", end=\"\")\n",
    "else:\n",
    "    print(\"greater than or equal to \", end=\"\")\n",
    "print(\"%.2f\" % observed_mean_diff, \".\")\n",
    "print(\"The chance of getting a difference of two means \", end=\"\")\n",
    "if observed_mean_diff < 0:\n",
    "    print(\"less than or equal to \", end=\"\")\n",
    "else:\n",
    "    print(\"greater than or equal to \", end=\"\")\n",
    "print(\"%.2f\" % observed_mean_diff, \"is\", (count / float(num_experiments)), \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's our p-value! Let's see it on a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.distplot(results, kde=False)\n",
    "plt.vlines(observed_mean_diff, 0, 120, colors=\"g\", linestyle=\"dashed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence intervals\n",
    "\n",
    "We'd like to know the amount of money Brinks owes the city, but there's not a good way to say exactly what that is. (Can you think of a way?)\n",
    "\n",
    "Even though our results were statistically significant, they might not even be important. What if Brinks employees stole $100/month? To NYC, the costs of taking the case to trial would dwarf that. _Confidence intervals_ show us importance. A confidence interval is simply the range of likely results. In general, this is the middle 90% of possible values.\n",
    "\n",
    "How do we get \"possible values?\" We can use a technique called \"bootstrapping\". We create samples of the data the same size as the original, taking observations randomly and _with replacement_. This means that we might pick the same observation more than once -- which is what we want. We do this 10,000 times, taking the difference of means each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meter_records.sample(n=10, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf_interval = 0.9\n",
    "num_experiments = 1000\n",
    "results = []\n",
    "for _ in range(num_experiments):\n",
    "    df = meter_records.sample(frac=1, replace=True)\n",
    "    mean_diff = mean_revenue_diff(df)\n",
    "    results.append(mean_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.sort()\n",
    "tails = (1 - conf_interval) / 2\n",
    "lower_bound = int(math.ceil(num_experiments * tails))\n",
    "upper_bound = int(math.floor(num_experiments * (1 - tails)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Observed difference between the means: %.2f\" % observed_mean_diff)\n",
    "print(\"We have %d%% confidence that the true difference between the means is between: %.2f and %.2f\" % \\\n",
    "      (conf_interval * 100, results[lower_bound], results[upper_bound]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't get us an amount of dollars, though. How could we do that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do amount of dollars calculations here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "https://speakerdeck.com/jakevdp/statistics-for-hackers\n",
    "http://www.amazon.com/Statistics-Edition-Synthesis-Lectures-Mathematics/dp/160845570X/ref=dp_ob_title_bk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
